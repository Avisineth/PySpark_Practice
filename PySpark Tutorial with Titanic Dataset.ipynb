{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6c2d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-SO7KC2K:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a20e090890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) #This is used to format output tables better\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4065398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr>\n",
       "<tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen ...</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. Joh...</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr>\n",
       "<tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. ...</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Ja...</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr>\n",
       "<tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. Willia...</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>6</td><td>0</td><td>3</td><td>Moran, Mr. James</td><td>male</td><td>null</td><td>0</td><td>0</td><td>330877</td><td>8.4583</td><td>null</td><td>Q</td></tr>\n",
       "<tr><td>7</td><td>0</td><td>1</td><td>McCarthy, Mr. Tim...</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>17463</td><td>51.8625</td><td>E46</td><td>S</td></tr>\n",
       "<tr><td>8</td><td>0</td><td>3</td><td>Palsson, Master. ...</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>349909</td><td>21.075</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>9</td><td>1</td><td>3</td><td>Johnson, Mrs. Osc...</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>10</td><td>1</td><td>2</td><td>Nasser, Mrs. Nich...</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>237736</td><td>30.0708</td><td>null</td><td>C</td></tr>\n",
       "<tr><td>11</td><td>1</td><td>3</td><td>Sandstrom, Miss. ...</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>PP 9549</td><td>16.7</td><td>G6</td><td>S</td></tr>\n",
       "<tr><td>12</td><td>1</td><td>1</td><td>Bonnell, Miss. El...</td><td>female</td><td>58.0</td><td>0</td><td>0</td><td>113783</td><td>26.55</td><td>C103</td><td>S</td></tr>\n",
       "<tr><td>13</td><td>0</td><td>3</td><td>Saundercock, Mr. ...</td><td>male</td><td>20.0</td><td>0</td><td>0</td><td>A/5. 2151</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>14</td><td>0</td><td>3</td><td>Andersson, Mr. An...</td><td>male</td><td>39.0</td><td>1</td><td>5</td><td>347082</td><td>31.275</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>15</td><td>0</td><td>3</td><td>Vestrom, Miss. Hu...</td><td>female</td><td>14.0</td><td>0</td><td>0</td><td>350406</td><td>7.8542</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>16</td><td>1</td><td>2</td><td>Hewlett, Mrs. (Ma...</td><td>female</td><td>55.0</td><td>0</td><td>0</td><td>248706</td><td>16.0</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>17</td><td>0</td><td>3</td><td>Rice, Master. Eugene</td><td>male</td><td>2.0</td><td>4</td><td>1</td><td>382652</td><td>29.125</td><td>null</td><td>Q</td></tr>\n",
       "<tr><td>18</td><td>1</td><td>2</td><td>Williams, Mr. Cha...</td><td>male</td><td>null</td><td>0</td><td>0</td><td>244373</td><td>13.0</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>19</td><td>0</td><td>3</td><td>Vander Planke, Mr...</td><td>female</td><td>31.0</td><td>1</td><td>0</td><td>345763</td><td>18.0</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>20</td><td>1</td><td>3</td><td>Masselmani, Mrs. ...</td><td>female</td><td>null</td><td>0</td><td>0</td><td>2649</td><td>7.225</td><td>null</td><td>C</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
       "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
       "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
       "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
       "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
       "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
       "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
       "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
       "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
       "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
       "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
       "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
       "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
       "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
       "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
       "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
       "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "titanic_df = spark.read.csv(\"train.csv\", header = True, inferSchema = True)\n",
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2719e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identify the datatypes of columns\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906c6870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr>\n",
       "<tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen ...</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. Joh...</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr>\n",
       "<tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. ...</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Ja...</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr>\n",
       "<tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. Willia...</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
       "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shown the datas of 5 raw\n",
    "titanic_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d36b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PassengerId</th><th>Survived</th></tr>\n",
       "<tr><td>1</td><td>0</td></tr>\n",
       "<tr><td>2</td><td>1</td></tr>\n",
       "<tr><td>3</td><td>1</td></tr>\n",
       "<tr><td>4</td><td>1</td></tr>\n",
       "<tr><td>5</td><td>0</td></tr>\n",
       "<tr><td>6</td><td>0</td></tr>\n",
       "<tr><td>7</td><td>0</td></tr>\n",
       "<tr><td>8</td><td>0</td></tr>\n",
       "<tr><td>9</td><td>1</td></tr>\n",
       "<tr><td>10</td><td>1</td></tr>\n",
       "<tr><td>11</td><td>1</td></tr>\n",
       "<tr><td>12</td><td>1</td></tr>\n",
       "<tr><td>13</td><td>0</td></tr>\n",
       "<tr><td>14</td><td>0</td></tr>\n",
       "<tr><td>15</td><td>0</td></tr>\n",
       "<tr><td>16</td><td>1</td></tr>\n",
       "<tr><td>17</td><td>0</td></tr>\n",
       "<tr><td>18</td><td>1</td></tr>\n",
       "<tr><td>19</td><td>0</td></tr>\n",
       "<tr><td>20</td><td>1</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+--------+\n",
       "|PassengerId|Survived|\n",
       "+-----------+--------+\n",
       "|          1|       0|\n",
       "|          2|       1|\n",
       "|          3|       1|\n",
       "|          4|       1|\n",
       "|          5|       0|\n",
       "|          6|       0|\n",
       "|          7|       0|\n",
       "|          8|       0|\n",
       "|          9|       1|\n",
       "|         10|       1|\n",
       "|         11|       1|\n",
       "|         12|       1|\n",
       "|         13|       0|\n",
       "|         14|       0|\n",
       "|         15|       0|\n",
       "|         16|       1|\n",
       "|         17|       0|\n",
       "|         18|       1|\n",
       "|         19|       0|\n",
       "|         20|       1|\n",
       "+-----------+--------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select specific columns\n",
    "titanic_df.select('PassengerId', 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f04518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PassengerId</th><th>Survived</th></tr>\n",
       "<tr><td>1</td><td>0</td></tr>\n",
       "<tr><td>2</td><td>1</td></tr>\n",
       "<tr><td>3</td><td>1</td></tr>\n",
       "<tr><td>4</td><td>1</td></tr>\n",
       "<tr><td>5</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------+\n",
       "|PassengerId|Survived|\n",
       "+-----------+--------+\n",
       "|          1|       0|\n",
       "|          2|       1|\n",
       "|          3|       1|\n",
       "|          4|       1|\n",
       "|          5|       0|\n",
       "+-----------+--------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select specific area of data\n",
    "titanic_df.select('PassengerId', 'Survived').limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095a105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr>\n",
       "<tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. Joh...</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr>\n",
       "<tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. ...</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Ja...</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr>\n",
       "<tr><td>9</td><td>1</td><td>3</td><td>Johnson, Mrs. Osc...</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>12</td><td>1</td><td>1</td><td>Bonnell, Miss. El...</td><td>female</td><td>58.0</td><td>0</td><td>0</td><td>113783</td><td>26.55</td><td>C103</td><td>S</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
       "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
       "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select specific area of data\n",
    "titanic_df.where((titanic_df.Age > 25) & (titanic_df.Survived == 1)).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed56cfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>avg(Fare)</th></tr>\n",
       "<tr><td>32.2042079685746</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+\n",
       "|       avg(Fare)|\n",
       "+----------------+\n",
       "|32.2042079685746|\n",
       "+----------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the average of Fare\n",
    "titanic_df.agg({'Fare':'avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae50457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Pclass</th><th>avg(Fare)</th></tr>\n",
       "<tr><td>3</td><td>13.675550101832997</td></tr>\n",
       "<tr><td>2</td><td>20.66218315217391</td></tr>\n",
       "<tr><td>1</td><td>84.15468749999992</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+------------------+\n",
       "|Pclass|         avg(Fare)|\n",
       "+------+------------------+\n",
       "|     3|13.675550101832997|\n",
       "|     2| 20.66218315217391|\n",
       "|     1| 84.15468749999992|\n",
       "+------+------------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the average of Pclass in decending order\n",
    "titanic_df.groupBy('Pclass').agg({'Fare':'avg'}).orderBy('Pclass', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e39bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>avg(Fare)</th></tr>\n",
       "<tr><td>37.61960169491524</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+\n",
       "|        avg(Fare)|\n",
       "+-----------------+\n",
       "|37.61960169491524|\n",
       "+-----------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter the Age > 25 Passengers average of Fare\n",
    "titanic_df.filter(titanic_df.Age > 25).agg({'Fare':'avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c894e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py\", line 458, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 602, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 692, in reducer_override\n",
      "    return self._function_reduce(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 565, in _function_reduce\n",
      "    return self._dynamic_function_reduce(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 546, in _dynamic_function_reduce\n",
      "    state = _function_getstate(func)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 157, in _function_getstate\n",
      "    f_globals_ref = _extract_code_globals(func.__code__)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 334, in _extract_code_globals\n",
      "    out_names = {names[oparg]: None for _, oparg in _walk_global_ops(co)}\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 334, in <dictcomp>\n",
      "    out_names = {names[oparg]: None for _, oparg in _walk_global_ops(co)}\n",
      "                 ~~~~~^^^^^^^\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: IndexError: tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py:458\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[0;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:602\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:692\u001b[0m, in \u001b[0;36mCloudPickler.reducer_override\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# fallback to save_global, including the Pickler's\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:565\u001b[0m, in \u001b[0;36mCloudPickler._function_reduce\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamic_function_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:546\u001b[0m, in \u001b[0;36mCloudPickler._dynamic_function_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    545\u001b[0m newargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_getnewargs(func)\n\u001b[1;32m--> 546\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43m_function_getstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (types\u001b[38;5;241m.\u001b[39mFunctionType, newargs, state, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    548\u001b[0m         _function_setstate)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:157\u001b[0m, in \u001b[0;36m_function_getstate\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m slotstate \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__qualname__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__closure__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__closure__\u001b[39m,\n\u001b[0;32m    155\u001b[0m }\n\u001b[1;32m--> 157\u001b[0m f_globals_ref \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_code_globals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__code__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m f_globals \u001b[38;5;241m=\u001b[39m {k: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f_globals_ref \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    159\u001b[0m              func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:334\u001b[0m, in \u001b[0;36m_extract_code_globals\u001b[1;34m(co)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# We use a dict with None values instead of a set to get a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# deterministic order (assuming Python 3.6+) and avoid introducing\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# non-deterministic pickle bytes as a results.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m out_names \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43moparg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moparg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_walk_global_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mco\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Declaring a function inside another one using the \"def ...\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# syntax generates a constant code object corresponding to the one\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# of the nested function's As the nested function may itself need\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# global variables, we need to introspect its code, extract its\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# globals, (look for code object in it's co_consts attribute..) and\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# add the result to code_globals\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:334\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# We use a dict with None values instead of a set to get a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# deterministic order (assuming Python 3.6+) and avoid introducing\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# non-deterministic pickle bytes as a results.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m out_names \u001b[38;5;241m=\u001b[39m {\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43moparg\u001b[49m\u001b[43m]\u001b[49m: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _, oparg \u001b[38;5;129;01min\u001b[39;00m _walk_global_ops(co)}\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Declaring a function inside another one using the \"def ...\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# syntax generates a constant code object corresponding to the one\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# of the nested function's As the nested function may itself need\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# global variables, we need to introspect its code, extract its\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# globals, (look for code object in it's co_consts attribute..) and\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# add the result to code_globals\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(x)\n\u001b[0;32m      7\u001b[0m round_float_down_udf \u001b[38;5;241m=\u001b[39m udf(round_float_down, IntegerType())\n\u001b[1;32m----> 9\u001b[0m titanic_df\u001b[38;5;241m.\u001b[39mselect(\u001b[43mround_float_down_udf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFare\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\udf.py:276\u001b[0m, in \u001b[0;36mUserDefinedFunction._wrapped.<locals>.wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, assigned\u001b[38;5;241m=\u001b[39massignments)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\udf.py:249\u001b[0m, in \u001b[0;36mUserDefinedFunction.__call__\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m    247\u001b[0m     judf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_judf(func)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 249\u001b[0m     judf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_judf\u001b[49m\n\u001b[0;32m    251\u001b[0m jPythonUDF \u001b[38;5;241m=\u001b[39m judf\u001b[38;5;241m.\u001b[39mapply(_to_seq(sc, cols, _to_java_column))\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\udf.py:215\u001b[0m, in \u001b[0;36mUserDefinedFunction._judf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_judf\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JavaObject:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# It is possible that concurrent access, to newly created UDF,\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# will initialize multiple UserDefinedPythonFunctions.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# This is unlikely, doesn't affect correctness,\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# and should have a minimal performance impact.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_judf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\udf.py:224\u001b[0m, in \u001b[0;36mUserDefinedFunction._create_judf\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    221\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39m_getActiveSessionOrCreate()\n\u001b[0;32m    222\u001b[0m sc \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\n\u001b[1;32m--> 224\u001b[0m wrapped_func \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturnType\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m jdt \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mparseDataType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnType\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\udf.py:50\u001b[0m, in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, returnType)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_function\u001b[39m(\n\u001b[0;32m     47\u001b[0m     sc: SparkContext, func: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any], returnType: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataTypeOrString\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JavaObject:\n\u001b[0;32m     49\u001b[0m     command \u001b[38;5;241m=\u001b[39m (func, returnType)\n\u001b[1;32m---> 50\u001b[0m     pickled_command, broadcast_vars, env, includes \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_for_python_RDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonFunction(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28mbytearray\u001b[39m(pickled_command),\n\u001b[0;32m     54\u001b[0m         env,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m         sc\u001b[38;5;241m.\u001b[39m_javaAccumulator,\n\u001b[0;32m     60\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\rdd.py:3345\u001b[0m, in \u001b[0;36m_prepare_for_python_RDD\u001b[1;34m(sc, command)\u001b[0m\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_python_RDD\u001b[39m(sc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkContext\u001b[39m\u001b[38;5;124m\"\u001b[39m, command: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, Any, Any, Any]:\n\u001b[0;32m   3343\u001b[0m     \u001b[38;5;66;03m# the serialized command will be compressed by broadcast\u001b[39;00m\n\u001b[0;32m   3344\u001b[0m     ser \u001b[38;5;241m=\u001b[39m CloudPickleSerializer()\n\u001b[1;32m-> 3345\u001b[0m     pickled_command \u001b[38;5;241m=\u001b[39m \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3346\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pickled_command) \u001b[38;5;241m>\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetBroadcastThreshold(sc\u001b[38;5;241m.\u001b[39m_jsc):  \u001b[38;5;66;03m# Default 1M\u001b[39;00m\n\u001b[0;32m   3348\u001b[0m         \u001b[38;5;66;03m# The broadcast will have same life cycle as created PythonRDD\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py:468\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    466\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not serialize object: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, emsg)\n\u001b[0;32m    467\u001b[0m print_exec(sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m--> 468\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPicklingError(msg)\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not serialize object: IndexError: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#Error-PicklingError: Could not serialize object: IndexError: tuple index out of range\n",
    "#This code cannot run because my laptop has the Python 3.11.0 version, and I think this error is with the Python version.\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def round_float_down(x):\n",
    "    return int(x)\n",
    "\n",
    "round_float_down_udf = udf(round_float_down, IntegerType())\n",
    "\n",
    "titanic_df.select(round_float_down_udf('Fare'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aafb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.createOrReplaceTempView(\"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1351c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr>\n",
       "<tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen ...</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. Joh...</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr>\n",
       "<tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. ...</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Ja...</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr>\n",
       "<tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. Willia...</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>6</td><td>0</td><td>3</td><td>Moran, Mr. James</td><td>male</td><td>null</td><td>0</td><td>0</td><td>330877</td><td>8.4583</td><td>null</td><td>Q</td></tr>\n",
       "<tr><td>7</td><td>0</td><td>1</td><td>McCarthy, Mr. Tim...</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>17463</td><td>51.8625</td><td>E46</td><td>S</td></tr>\n",
       "<tr><td>8</td><td>0</td><td>3</td><td>Palsson, Master. ...</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>349909</td><td>21.075</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>9</td><td>1</td><td>3</td><td>Johnson, Mrs. Osc...</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>10</td><td>1</td><td>2</td><td>Nasser, Mrs. Nich...</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>237736</td><td>30.0708</td><td>null</td><td>C</td></tr>\n",
       "<tr><td>11</td><td>1</td><td>3</td><td>Sandstrom, Miss. ...</td><td>female</td><td>4.0</td><td>1</td><td>1</td><td>PP 9549</td><td>16.7</td><td>G6</td><td>S</td></tr>\n",
       "<tr><td>12</td><td>1</td><td>1</td><td>Bonnell, Miss. El...</td><td>female</td><td>58.0</td><td>0</td><td>0</td><td>113783</td><td>26.55</td><td>C103</td><td>S</td></tr>\n",
       "<tr><td>13</td><td>0</td><td>3</td><td>Saundercock, Mr. ...</td><td>male</td><td>20.0</td><td>0</td><td>0</td><td>A/5. 2151</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>14</td><td>0</td><td>3</td><td>Andersson, Mr. An...</td><td>male</td><td>39.0</td><td>1</td><td>5</td><td>347082</td><td>31.275</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>15</td><td>0</td><td>3</td><td>Vestrom, Miss. Hu...</td><td>female</td><td>14.0</td><td>0</td><td>0</td><td>350406</td><td>7.8542</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>16</td><td>1</td><td>2</td><td>Hewlett, Mrs. (Ma...</td><td>female</td><td>55.0</td><td>0</td><td>0</td><td>248706</td><td>16.0</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>17</td><td>0</td><td>3</td><td>Rice, Master. Eugene</td><td>male</td><td>2.0</td><td>4</td><td>1</td><td>382652</td><td>29.125</td><td>null</td><td>Q</td></tr>\n",
       "<tr><td>18</td><td>1</td><td>2</td><td>Williams, Mr. Cha...</td><td>male</td><td>null</td><td>0</td><td>0</td><td>244373</td><td>13.0</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>19</td><td>0</td><td>3</td><td>Vander Planke, Mr...</td><td>female</td><td>31.0</td><td>1</td><td>0</td><td>345763</td><td>18.0</td><td>null</td><td>S</td></tr>\n",
       "<tr><td>20</td><td>1</td><td>3</td><td>Masselmani, Mrs. ...</td><td>female</td><td>null</td><td>0</td><td>0</td><td>2649</td><td>7.225</td><td>null</td><td>C</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
       "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
       "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
       "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
       "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
       "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
       "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
       "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
       "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
       "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
       "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
       "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
       "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
       "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
       "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
       "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
       "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('select * from Titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece624c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
